"""
Algorithm to compute required articles applying the pagerank algorithm to a graph generated by 
tranversing the target article by a few levels.
"""
#Import libs
import sys

import py2neo
from py2neo import Graph

import networkx as nx


from tabulate import tabulate

#import matplotlib.pyplot as plt



#Functions

#Function to compute incomming edges
#replaced by lib in_centrality


#Function to get the article cluster
def getArticleClusters(articleTitle, transversalLevel, deleteMainNode, clusterAllocMethod, clusterRankMethod, neo4jGraph, verbose):

    #Create a directed graph
    G = nx.DiGraph()

    #All directions query based on forward nodes
    #Query all nodes id related
    dbQuery = " ".join([
        'MATCH (n1:Article {name:"ARTICLE-TITLE"})-[l1:RefersTo*TRANSVERSAL-LEVEL]->(n2:Article)',
        'RETURN collect(DISTINCT ID(n1)) + collect(DISTINCT ID(n2)) as ids'
    ]).replace("ARTICLE-TITLE", articleTitle).replace("TRANSVERSAL-LEVEL", transversalLevel)

    nodeIds = [] #Array to keep node ids

    if verbose:
        print "Querying ids..."

    #Execute query and compute ids
    for r in neo4jGraph.run(dbQuery):
        nodeIds += r['ids']

    #Now query all connectTo relations between these nodes
    dbQuery = " ".join([
        'MATCH (n1:Article)-[l1:RefersTo]-(n2:Article)',
        'WHERE (ID(n1) IN NODE-IDS AND ID(n2) IN NODE-IDS)',
        'RETURN l1 as edges'
    ]).replace("NODE-IDS", str(nodeIds))

    if verbose:
        print "Querying edges..."

    #Execute query and add edges to create graph
    if verbose:
        print "Creating graph..."
    for val in neo4jGraph.run(dbQuery):
        e = val[0]
        G.add_edge(e.start_node()['name'], e.end_node()['name'])

    #Delete main node if it is needed
    if deleteMainNode:
        if verbose:
            print "Deleting main node..."
        G.remove_node(articleTitle)



    #comps = nx.k_components(G.to_undirected())

    #comps = nx.all_node_cuts(G.to_undirected())

    #comps = nx.edge_connectivity(G)

    #comps = nx.minimum_node_cut(G)

    
    comps = []
    #print comps
    #sys.exit()

    print ""
    for i in comps:
        comp = comps[i]
        for member in comp:
            print member
        print ""

    



    #centrality = nx.degree_centrality(G)

    centrality = nx.in_degree_centrality(G)

    pagerank = nx.pagerank(G)


    #think how to construct things by this

    #use degree centrality 

    #think if the current approach is good
    #check if we use clusters or not
    #clusters are good to take the most variate areas of the knowledge
    #think fitness function to cluster

    #maybe clusters wont work due to non fitness function clear for them
    #just use degree centrality

    #centrality = nx.closeness_centrality(G)

    #centrality = nx.betweenness_centrality(G)

    #centrality = nx.edge_betweenness_centrality(G)

    #centrality = nx.current_flow_betweenness_centrality(G)

    #centrality = nx.edge_current_flow_betweenness_centrality(G)

    #centrality = nx.approximate_current_flow_betweenness_centrality(G)

    #centrality = nx.eigenvector_centrality(G) nada ve

    #centrality = nx.eigenvector_centrality_numpy(G)

    #centrality = nx.katz_centrality(G)

    #centrality = nx.katz_centrality_numpy(G)

    


    def sortConcatAndPrint(dict1, dict2):

        #Sort
        sortedDict1 = sorted(dict1.items(), key=lambda a: a[1], reverse=False)
        sortedDict2 = sorted(dict2.items(), key=lambda a: a[1], reverse=False)

        #Concatenate
        dictSize = len(sortedDict1)
        printData = list()
        for i in xrange(dictSize):
            #Convert data to list to be editable
            sortedDict1[i] = list(sortedDict1[i])
            sortedDict2[i] = list(sortedDict2[i])

            #Truncate too long string
            sortedDict1[i][0] = sortedDict1[i][0][:40]
            sortedDict2[i][0] = sortedDict2[i][0][:40]

            #Round decimal values to fit on screen
            sortedDict1[i][1] = round(sortedDict1[i][1], 2)
            sortedDict2[i][1] = round(sortedDict2[i][1], 2)

            printData.append([str(sortedDict1[i]), str(sortedDict2[i])])

        #Print
        print(tabulate(printData, headers=['PageRank', 'InCentrality']))



    def sortAndPrint(items):
        sortedItems = sorted(items.items(), key=lambda a: a[1], reverse=False)
        for d in sortedItems:
            print d.encode('ascii', 'ignore')
    

    sortConcatAndPrint(pagerank, centrality)

    #print ""
    #sortAndPrint(centrality)

    #print ""
    #sortAndPrint(pagerank)

    sys.exit()



    if verbose:
        print "Generating clusters..."

    #Get the connected nodes of G according to choose method
    if clusterAllocMethod == 'weak':
        clusters_nodes = nx.weakly_connected_components(G)
    elif clusterAllocMethod == 'strong':
        clusters_nodes = nx.strongly_connected_components(G)

    if verbose:
        print "Getting clusters graphs..."

    clusters_subgraphs = [G.subgraph(nlist) for nlist in clusters_nodes]

    #Array to keep the clusters
    clusters = []

    #Iterate thru the clusters subgraphs
    for cluster_sg in clusters_subgraphs:

        #Calculate the rank for each node in the cluster
        if clusterRankMethod == 'pagerank':
            cluster_node_ranks = nx.pagerank(cluster_sg).items() #Pagerank
        elif clusterRankMethod == 'sum':
            cluster_node_ranks = in_degree_centrality(cluster_sg).items() #Incomming edges

        #Order cluster in decreasing order
        cluster_node_ranks = sorted(cluster_node_ranks, key=lambda a: a[1], reverse=True) 

        #Append the cluster to the clusters array with its length
        clusters.append((cluster_node_ranks, len(cluster_node_ranks)))

    #Order clusters in decreasing order
    clusters = sorted(clusters, key=lambda a: a[1], reverse=True) 

    return clusters



#--------------main()-----------------
if __name__ == "__main__":

    print "Initing db..."

    #Load database
    py2neo.authenticate("localhost:7474", "neo4j", "lucas")
    neo4jGraph = Graph("http://localhost:7474/db/data/")

    #Default Configuration
    articleTitle = "MQTT" #Article to generate graph from
    transversalLevel = "1..3" #Graph transversal level 
    deleteMainNode = True #Exclude the main node in the cluster computation
    clusterAllocMethod = "weak" # 'weak' for weakly-connnected-components and 'strong' for strongly-connected-components
    clusterRankMethod = "sum" #'sum' to simply sum incomming nodes and 'pagerank' to compute nodes pageranks
    #betweenNodesConnections #TO BE IMPLEMENTED Whether to get connections between graph nodes or only their forward connections

    #Replace configs
    try: 
        articleTitle = sys.argv[1]
    except: 
        pass

    try:
        transversalLevel = sys.argv[2]
    except: 
        pass

    try:
        clusterAllocMethod = sys.argv[3]
    except: 
        pass

    try:
        clusterRankMethod = sys.argv[4]
    except: 
        pass


    clusters = getArticleClusters(articleTitle, transversalLevel, True, clusterAllocMethod, clusterRankMethod, neo4jGraph, True)


    #String to store the result of the process
    resultLog = ""

    #Iterate thru clusters
    for c in clusters:
        resultLog += "Cluster nodes: " + str(c[1]) + "\n\r"
        for node in c[0]:
            resultLog += str(node) + "\n\r"
        resultLog += "\n\r"

    #Save result log with its properties
    fileName = "-".join([articleTitle, transversalLevel, str(deleteMainNode), clusterAllocMethod, clusterRankMethod]) + ".txt"
    with open("results/" + fileName, "w") as f:
        f.write(resultLog)
    f.close()

    print ""
    print resultLog

    # nx.draw(G)
    # plt.show()